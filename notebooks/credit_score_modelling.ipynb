{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n",
      "                     Accuracy  Precision    Recall  F1 Score   ROC-AUC\n",
      "Logistic Regression  0.998171   0.576923  0.384615  0.461538  0.988602\n",
      "Decision Tree        0.999373   0.909091  0.769231  0.833333  0.884577\n",
      "Random Forest        0.999530   0.941176  0.820513  0.876712  0.999874\n",
      "Gradient Boosting    0.999425   0.937500  0.769231  0.845070  0.871664\n",
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Random Forest Metrics:\n",
      "{'Accuracy': 0.9994773428108503, 'Precision': 0.9142857142857143, 'Recall': 0.8205128205128205, 'F1 Score': 0.8648648648648649, 'ROC-AUC': np.float64(0.9998549685362297)}\n",
      "✅ Best Random Forest model saved at: ../saved_models/best_random_forest.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Load the processed dataset\n",
    "processed_file_path = \"../data/processed_credit_scoring_data.csv\"\n",
    "df = pd.read_csv(processed_file_path)\n",
    "\n",
    "# 2. Fix the target variable (if necessary)\n",
    "# Example: Map 22 to 1\n",
    "df[\"FraudResult\"] = df[\"FraudResult\"].replace({22: 1})\n",
    "\n",
    "# 3. Drop non-numeric columns\n",
    "non_numeric_cols = [\"TransactionId\", \"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"TransactionStartTime\", \"FraudResult\", \"Risk_Label\"]\n",
    "X = df.drop(columns=non_numeric_cols)\n",
    "y = df[\"FraudResult\"]  # Target variable\n",
    "\n",
    "# 4. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 5. Train and evaluate models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "evaluation_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    evaluation_results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "        \"Recall\": recall_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(evaluation_results).T\n",
    "print(results_df)\n",
    "\n",
    "# 6. Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring=\"roc_auc\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_pred_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "best_rf_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "    \"Recall\": recall_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "    \"F1 Score\": f1_score(y_test, y_pred, pos_label=1),  # Specify pos_label=1\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_pred_proba)\n",
    "}\n",
    "\n",
    "print(\"Best Random Forest Metrics:\")\n",
    "print(best_rf_metrics)\n",
    "# Define directory to store models\n",
    "MODEL_DIR = \"../saved_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Save the best Random Forest model\n",
    "model_path = os.path.join(MODEL_DIR, \"best_random_forest.joblib\")\n",
    "joblib.dump(best_rf, model_path)\n",
    "\n",
    "print(f\"✅ Best Random Forest model saved at: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envcredit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
